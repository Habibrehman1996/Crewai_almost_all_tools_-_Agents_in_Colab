{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibrehman1996/Crewai_almost_all_tools_-_Agents_in_Colab/blob/main/01_Crewai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import API KEY"
      ],
      "metadata": {
        "id": "WL8rGU36tgCQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REk3Nj6vm2eR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#INSTALL CREWAI TOOLS"
      ],
      "metadata": {
        "id": "FskGOuvytoI6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25q5hGSjDsUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e10b9d-30f2-41f6-e920-b963b5eaa835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.2/240.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.9/545.9 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.6/32.6 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq crewai crewai-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dttwCawWD0uf"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te4kRgf-D6XF",
        "outputId": "6d866768-fa9e-4dd1-9c81-3a61a8f6872e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[35m Flow started with ID: 49dd5987-04c7-4874-94bb-eb465ad3fd45\u001b[00m\n",
            "Daniyal\n",
            "Salman\n"
          ]
        }
      ],
      "source": [
        "from crewai.flow.flow import Flow, start, listen\n",
        "\n",
        "class MyFlow(Flow):\n",
        "\n",
        "  @start()\n",
        "  def function1(self):\n",
        "    print(\"Daniyal\")\n",
        "\n",
        "  @listen(function1)\n",
        "  def function2(self):\n",
        "    print(\"Salman\")\n",
        "\n",
        "obj = MyFlow()\n",
        "obj.kickoff()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connect And Import LLM"
      ],
      "metadata": {
        "id": "3cmjg3DNtv4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J7QJzzZiECOM",
        "outputId": "b57d014d-d6da-46af-cd78-52d25140fd6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hamas was co-founded in 1987 by Sheikh Ahmed Yassin and Abdel Aziz al-Rantissi, shortly after the start of the First Intifada.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from crewai import LLM\n",
        "llm1 = LLM(\n",
        "    model=\"gemini/gemini-2.0-flash\"\n",
        "\n",
        ")\n",
        "llm1.call(\"who is the founder of Hamas?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedder"
      ],
      "metadata": {
        "id": "zuVAPze1t273"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCoZxQE3d1Kp"
      },
      "outputs": [],
      "source": [
        "google_embedder ={\n",
        "    \"provider\": \"google\",\n",
        "    \"config\": {\n",
        "        \"model\": \"models/text-embedding-004\",\n",
        "        \"api_key\": userdata.get('GOOGLE_API_KEY'),\n",
        "    }\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jD8wu-e-kR-"
      },
      "source": [
        "#Crewai Knowledge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "fuJExIoYbnMb",
        "outputId": "e0ed6f84-b7a6-4189-b558-b4484ae4c785"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/colab/html/_background_server.py:103: DeprecationWarning: make_current is deprecated; start the event loop first\n",
            "  ioloop.make_current()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mAnswer the following questions about the user: What city does Habib live in and how old is he and what is his disignation?\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Habib lives in Karachi, he is 28 years old, and his designation is HOD (Head of Department) in Taqwa Schooling System.\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
        "\n",
        "# Create a knowledge source\n",
        "content = \"Users name is Habib. He is 28 years old and lives in Karachi.He is working as a HOD in Taqwa Schooling System \"\n",
        "string_source = StringKnowledgeSource(\n",
        "    content=content,\n",
        ")\n",
        "\n",
        "# Create an LLM with a temperature of 0 to ensure deterministic outputs\n",
        "llm = LLM(model=\"gemini/gemini-2.0-flash\", temperature=0)\n",
        "\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    verbose=True,\n",
        "    process=Process.sequential,\n",
        "    knowledge_sources=[string_source], # Enable knowledge by adding the sources here. You can also add more sources to the sources list.\n",
        "    embedder=google_embedder\n",
        ")\n",
        "\n",
        "result = crew.kickoff(inputs={\"question\": \"What city does Habib live in and how old is he and what is his disignation?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Crew_Storage_Dir"
      ],
      "metadata": {
        "id": "vvy3Y99puKDa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUBuPQlhCzz-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CREWAI_STORAGE_DIR']='/my_crew2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH4yAmDiHJIq"
      },
      "outputs": [],
      "source": [
        "from crewai import LLM\n",
        "\n",
        "llm1 = LLM(\n",
        "    model = \"gemini/gemini-2.0-flash\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH8UPsyn-exM"
      },
      "source": [
        "#Crew RAG Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-nJ7xGuH2RV",
        "outputId": "5e08b3af-5057-4830-a23b-d070f63b6532"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ],
      "source": [
        "from crewai import Crew, Process\n",
        "from crewai.memory import LongTermMemory, ShortTermMemory, EntityMemory\n",
        "#from crewai.memory.storage import LTMSQLiteStorage, RAGStorage\n",
        "from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n",
        "from crewai.memory.storage.rag_storage import RAGStorage\n",
        "from typing import List, Optional\n",
        "\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "# Assemble your crew with memory capabilities\n",
        "Crew = Crew(\n",
        "    agents = [agent],\n",
        "    tasks = [task],\n",
        "    process = Process.sequential,\n",
        "    memory = True,\n",
        "    # Long-term memory for persistent storage across sessions\n",
        "    long_term_memory = LongTermMemory(\n",
        "        storage=LTMSQLiteStorage(\n",
        "            db_path=\"./my_crew2/long_term_memory_storage.db\"\n",
        "        )\n",
        "    ),\n",
        "    # Short-term memory for current context using RAG\n",
        "    short_term_memory = ShortTermMemory(\n",
        "        storage = RAGStorage(\n",
        "                embedder_config=google_embedder,\n",
        "                type=\"short_term\",\n",
        "                path=\"./my_crew2/short_term1/\"\n",
        "\n",
        "        )\n",
        "    ),\n",
        "    # Entity memory for tracking key information about entities\n",
        "    entity_memory = EntityMemory(\n",
        "        storage=RAGStorage(\n",
        "            embedder_config=google_embedder,\n",
        "            type=\"short_term\",\n",
        "            path=\"./my_crew2/entity1/\"\n",
        "        )\n",
        "    ),\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weCVAhyI-Yc9"
      },
      "source": [
        "#Crew Memory Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEuabBZCOTBL",
        "outputId": "0ab4a820-547b-4ace-cc2e-5128d45966d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mAnswer the following questions about the user: what is your favorite vacation destination?\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Based on your preference for beach destinations and Airbnb, I would recommend considering a vacation to the Outer Banks in North Carolina. The Outer Banks offers beautiful beaches, a variety of Airbnb rentals, and opportunities for relaxation and water activities.\u001b[00m\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mem0/client/main.py:32: DeprecationWarning: Using default output format 'v1.0' is deprecated and will be removed in version 0.1.70. Please use output_format='v1.1' for enhanced memory details. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/mem0/client/main.py:32: DeprecationWarning: Using default output format 'v1.0' is deprecated and will be removed in version 0.1.70. Please use output_format='v1.1' for enhanced memory details. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CrewOutput(raw='Based on your preference for beach destinations and Airbnb, I would recommend considering a vacation to the Outer Banks in North Carolina. The Outer Banks offers beautiful beaches, a variety of Airbnb rentals, and opportunities for relaxation and water activities.', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Answer the following questions about the user: what is your favorite vacation destination?', name=None, expected_output='An answer to the question.', summary='Answer the following questions about the user: what is your...', raw='Based on your preference for beach destinations and Airbnb, I would recommend considering a vacation to the Outer Banks in North Carolina. The Outer Banks offers beautiful beaches, a variety of Airbnb rentals, and opportunities for relaxation and water activities.', pydantic=None, json_dict=None, agent='About User', output_format=<OutputFormat.RAW: 'raw'>)], token_usage=UsageMetrics(total_tokens=302, prompt_tokens=210, cached_prompt_tokens=0, completion_tokens=92, successful_requests=1))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from crewai import Crew, Process\n",
        "from mem0 import MemoryClient\n",
        "\n",
        "# Set environment variables for Mem0\n",
        "os.environ[\"MEM0_API_KEY\"] = userdata.get('MEM0_API_KEY')\n",
        "\n",
        "# Step 1: Record preferences based on past conversation or user input\n",
        "client = MemoryClient()\n",
        "# messages = [\n",
        "#     {\"role\": \"user\", \"content\": \"Hi there! I'm planning a vacation and could use some advice.\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to help with your vacation planning. What kind of destination do you prefer?\"},\n",
        "#     {\"role\": \"user\", \"content\": \"I am more of a beach person than a mountain person.\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"That's interesting. Do you like hotels or Airbnb?\"},\n",
        "#     {\"role\": \"user\", \"content\": \"I like Airbnb more.\"},\n",
        "# ]\n",
        "# client.add(messages, user_id=\"john\")\n",
        "\n",
        "# Step 2: Create a Crew with User Memory\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    verbose=True,\n",
        "    process=Process.sequential,\n",
        "    memory=True,\n",
        "    memory_config={\n",
        "        \"provider\": \"mem0\",\n",
        "        \"config\": {\"user_id\": \"john\"},\n",
        "    },\n",
        ")\n",
        "crew.kickoff(inputs={\"question\": \"what is your favorite vacation destination?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THrXaUZFTsH2"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq 'crewai[tools]'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Serper_API_key"
      ],
      "metadata": {
        "id": "5_XIbfqZueyP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CubRn_aZT65M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get(\"SERPER_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgVBPMpqXgWr"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "class TeacherAssignmentOutPut(BaseModel):\n",
        "  score :int = Field(..., descrition = \"student assignment score\")\n",
        "  feedback :str = Field(..., descrition = \"Teacher Feedback \")\n",
        "  question :str = Field(..., descrition = \"question\")\n",
        "  answer :str = Field(..., descrition = \"python code for markdown format\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDscLVa2-KXE"
      },
      "source": [
        "#AI Teacher Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RICfBciNPXxz",
        "outputId": "439d91a9-3304-435e-8fe6-949c4d59e4cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI Teacher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mYou are AI teacher you can check python assingnment code submition. question:  create function add two numbers student solution: \n",
            "def add_two_number(num1 : int, num2 : int):\n",
            "  return num1 + num2\n",
            " \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI Teacher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to check the student's code for correctness, style, and adherence to the prompt. The prompt asks for a function that adds two numbers. The student provided a function that appears to do just that. I will execute the code with some test values to ensure it works correctly. I will also provide feedback on the code's style and clarity.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mCode Interpreter\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"code\\\": \\\"def add_two_number(num1 : int, num2 : int):\\\\n  return num1 + num2\\\\n\\\\n# Test cases\\\\nprint(add_two_number(1, 2))\\\\nprint(add_two_number(5, 5))\\\\nprint(add_two_number(10, 0))\\\", \\\"libraries_used\\\": []}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory')).\n",
            " Tool Code Interpreter accepts these inputs: Tool Name: Code Interpreter\n",
            "Tool Arguments: {'code': {'description': 'Python3 code used to be interpreted in the Docker container. ALWAYS PRINT the final result and the output of the code', 'type': 'str'}, 'libraries_used': {'description': 'List of libraries used in the code with proper installing names separated by commas. Example: numpy,pandas,beautifulsoup4', 'type': 'list[str]'}}\n",
            "Tool Description: Interprets Python3 code strings with a final print statement..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Code Interpreter]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI Teacher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mI will try again to execute the code.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mCode Interpreter\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"code\\\": \\\"def add_two_number(num1 : int, num2 : int):\\\\n  return num1 + num2\\\\n\\\\n# Test cases\\\\nprint(add_two_number(1, 2))\\\\nprint(add_two_number(5, 5))\\\\nprint(add_two_number(10, 0))\\\", \\\"libraries_used\\\": []}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory')).\n",
            " Tool Code Interpreter accepts these inputs: Tool Name: Code Interpreter\n",
            "Tool Arguments: {'code': {'description': 'Python3 code used to be interpreted in the Docker container. ALWAYS PRINT the final result and the output of the code', 'type': 'str'}, 'libraries_used': {'description': 'List of libraries used in the code with proper installing names separated by commas. Example: numpy,pandas,beautifulsoup4', 'type': 'list[str]'}}\n",
            "Tool Description: Interprets Python3 code strings with a final print statement..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Code Interpreter]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI Teacher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "{\n",
            "  \"score\": 5,\n",
            "  \"feedback\": \"The code is correct and well-written. The function `add_two_number` takes two integers as input and returns their sum, as expected. Good job! You could add a docstring to explain what the function does.\",\n",
            "  \"question\": \"create function add two numbers\",\n",
            "  \"answer\": \"def add_two_number(num1 : int, num2 : int):\\n  return num1 + num2\"\n",
            "}\u001b[00m\n",
            "\n",
            "\n",
            "score=5 feedback='The code is correct and well-written. The function `add_two_number` takes two integers as input and returns their sum, as expected. Good job! You could add a docstring to explain what the function does.' question='create function add two numbers' answer='def add_two_number(num1 : int, num2 : int):\\n  return num1 + num2'\n"
          ]
        }
      ],
      "source": [
        "from crewai import Agent\n",
        "from crewai_tools import CodeInterpreterTool\n",
        "from crewai import Task, Process, crew\n",
        "\n",
        "Teacher = Agent(\n",
        "    role=\"AI Teacher\",\n",
        "    goal=\"You are AI teacher you can check python assingnment code submition.\",\n",
        "    backstory=\"\"\"You have check student python code submition.\"\"\",\n",
        "    tools=[CodeInterpreterTool()],\n",
        "    llm=llm\n",
        ")\n",
        "Assignment_check = Task(\n",
        "    description=\"You are AI teacher you can check python assingnment code submition. question: \"\"{question}\"\" student solution: \"\"{solution}\"\" \",\n",
        "    expected_output=\"final code is runing, assign number between 1-10\",\n",
        "    output_pydantic=TeacherAssignmentOutPut,\n",
        "    agent=Teacher\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[Teacher],\n",
        "    tasks=[Assignment_check],\n",
        "    verbose=True,\n",
        "    process=Process.sequential,\n",
        "\n",
        ")\n",
        "question =\" create function add two numbers\"\n",
        "\n",
        "solution = \"\"\"\n",
        "def add_two_number(num1 : int, num2 : int):\n",
        "  return num1 + num2\n",
        "\"\"\"\n",
        "result = crew.kickoff(inputs={\n",
        "    \"question\": question,\n",
        "     \"solution\": solution\n",
        "    })\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk9s8phZQ8uW",
        "outputId": "dc0b1fcb-469f-4064-9524-11c7dff6d327"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 5,\n",
              " 'feedback': 'The code is correct and well-written. The function `add_two_number` takes two integers as input and returns their sum, as expected. Good job! You could add a docstring to explain what the function does.',\n",
              " 'question': 'create function add two numbers',\n",
              " 'answer': 'def add_two_number(num1 : int, num2 : int):\\n  return num1 + num2'}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPjLykCVXEaI",
        "outputId": "5eaf4eea-ef3b-4534-e9bf-6da747aa4575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FgzIFBkXc7C"
      },
      "outputs": [],
      "source": [
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm1=LLM(model=\"gemini/gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzGZKw4LgiQ8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWLeTWRt9-ax"
      },
      "source": [
        "#CrewaiTools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsiJvpErygw3",
        "outputId": "dfdb1fa8-ad0d-4522-8b0e-479c72731509"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[93m \n",
            "[2025-03-05 18:10:28][INFO]: Planning the crew execution\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mResearch the latest trends in the AI industry and provide a summary.Step 1: The Market Research Analyst will utilize the 'Search the internet with Serper' tool.  The search query will be crafted to be highly specific and effective, for example:  \"Top 3 AI industry trends 2024\", \"Most significant advancements in artificial intelligence\",  \"Breakthroughs in AI research this year\".  The analyst will ensure the search query is modified and iterated upon to refine the results, focusing on reputable sources like academic journals, industry publications (e.g., MIT Technology Review, IEEE Spectrum), and news from major technology companies. \n",
            "Step 2:  The analyst will carefully review the top 10 results (or adjust the number based on the relevance of initial results) provided by Serper, identifying common themes and unique perspectives across various sources.  They will prioritize high-quality, peer-reviewed articles and reputable news outlets to ensure accuracy and depth of analysis. \n",
            "Step 3:  The analyst will synthesize the information gathered, focusing on identifying the top three trending AI developments.  This summary should not just be a list; it should analyze the significance and potential impact of each trend, providing a unique perspective on their implications for the broader AI industry and other sectors. The summary should be concise and easily understandable, avoiding overly technical jargon.\n",
            "Step 4:  The analyst will review the summary for clarity, accuracy, and overall impact. They will ensure the unique perspective is clearly articulated and well-supported by the evidence gathered. The final summary will be concise, factual and insightful, ready for the content writer.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I need to use the \"Search the internet with Serper\" tool to gather information on the latest trends in the AI industry. I will use several search queries to ensure a comprehensive understanding.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"Top 3 AI industry trends 2024\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'Top 3 AI industry trends 2024', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Top 10: AI Trends in 2024 - AI Magazine', 'link': 'https://aimagazine.com/top10/top-10-ai-trends-in-2024', 'snippet': 'The biggest AI trends of 2024 included accessibility, ethics, sustainability and regulation, with companies like Google, NVIDIA and Amazon in leading roles.', 'position': 1}, {'title': 'The state of AI in early 2024 - McKinsey & Company', 'link': 'https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai', 'snippet': 'The state of AI in early 2024: Gen AI adoption spikes and starts to generate value. As generative AI adoption accelerates, survey respondents ...', 'position': 2}, {'title': 'The most important AI trends in 2024 - IBM', 'link': 'https://www.ibm.com/think/insights/artificial-intelligence-trends', 'snippet': 'The top three factors driving AI adoption were advances in AI tools that make them more accessible, the need to reduce costs and automate key processes.', 'position': 3}, {'title': 'AI Index Report 2024 – Artificial Intelligence Index - Stanford University', 'link': 'https://aiindex.stanford.edu/report/', 'snippet': '1. Industry continues to dominate frontier AI research. · 2. More foundation models and more open foundation models. · 3. Frontier models get way more expensive.', 'position': 4}, {'title': 'AI Pulse: Top AI Trends from 2024 - A Look Back | Trend Micro (US)', 'link': 'https://www.trendmicro.com/en_us/research/25/a/top-ai-trends-from-2024-review.html', 'snippet': 'Bridge digital divides · Make the digital economy inclusive · Ensure digital space(s) protect human rights · Advance good data governance · Enhance ...', 'position': 5}, {'title': \"IDC's 2024 AI opportunity study: Top five AI trends to watch - The ...\", 'link': 'https://blogs.microsoft.com/blog/2024/11/12/idcs-2024-ai-opportunity-study-top-five-ai-trends-to-watch/', 'snippet': '#1 Enhanced productivity has become table stakes. · #2 Companies are gravitating to more advanced AI solutions. · #3 Generative AI adoption and ...', 'position': 6}, {'title': '2024 Global Trends in AI - WEKA', 'link': 'https://www.weka.io/resources/analyst-report/2024-global-trends-in-ai/', 'snippet': 'Discover key AI trends in 2024. Explore generative AI, scaling challenges, GPU demand, and sustainable practices. Download the S&P Global report.', 'position': 7}, {'title': '131 AI Statistics and Trends for (2024) | National University', 'link': 'https://www.nu.edu/blog/ai-statistics-trends/', 'snippet': 'AI Jobs and Market · Customer service – 56% · Cybersecurity and fraud management – 51% · Digital personal assistants – 47% · Customer relationship management – 46% ...', 'position': 8, 'sitelinks': [{'title': 'Ai Demographics', 'link': 'https://www.nu.edu/blog/ai-statistics-trends/#:~:text=AI%20Demographics,-Understanding%20the%20demographics%20behind%20AI'}, {'title': 'Ai Jobs And Market', 'link': 'https://www.nu.edu/blog/ai-statistics-trends/#:~:text=AI%20Jobs%20and%20Market'}, {'title': 'Ai And User Trust', 'link': 'https://www.nu.edu/blog/ai-statistics-trends/#:~:text=AI%20and%20User%20Trust'}]}, {'title': '5 AI Trends to Watch in 2025 | Coursera', 'link': 'https://www.coursera.org/articles/ai-trends', 'snippet': '1. Generative AI and democratization · 2. AI for workplace productivity · 3. Multimodal AI · 4. AI in science and health care · 5. Regulation and ...', 'position': 9, 'sitelinks': [{'title': '5 Trends In Artificial...', 'link': 'https://www.coursera.org/articles/ai-trends#:~:text=5%20trends%20in%20artificial%20intelligence'}, {'title': '1. Generative Ai And...', 'link': 'https://www.coursera.org/articles/ai-trends#:~:text=1.%20Generative%20AI%20and%20democratization'}, {'title': 'Start Learning Ai Today', 'link': 'https://www.coursera.org/articles/ai-trends#:~:text=Start%20learning%20AI%20today'}]}, {'title': 'What are the latest trends in artificial intelligence for 2024?', 'link': 'https://techaifuturism.quora.com/What-are-the-latest-trends-in-artificial-intelligence-for-2024?top_ans=1477743767920050', 'snippet': 'From robotic process automation (RPA) to intelligent chatbots and virtual assistants, AI is automating repetitive tasks, enhancing productivity, ...', 'position': 10}], 'peopleAlsoAsk': [{'question': 'What is one of the key AI trends for 2024?', 'snippet': \"The 2024 AI trends showed us that AI isn't just an experiment— it's becoming an integral part of our business operations and in our society. Generative AI is now a daily tool, multimodal AI simplifies content creation, and reasoning AI solves real-world problems.\", 'title': \"2024 Recap: AI Trends That Redefined What's Possible\", 'link': 'https://www.neudesic.com/blog/2024-recap-ai-trends/'}, {'question': 'What are the top AI technologies in 2024?', 'snippet': 'Customized local models and data pipelines\\\\n\\\\n Open source models afford organizations the opportunity to develop powerful custom AI models—trained on their proprietary data and fine-tuned for their specific needs—quickly, without prohibitively expensive infrastructure investments.', 'title': 'The most important AI trends in 2024 - IBM', 'link': 'https://www.ibm.com/think/insights/artificial-intelligence-trends'}, {'question': 'What is the biggest AI news of 2024?', 'snippet': \"On December 17, 2024, US-based AI cloud data platform Databricks announced it had raised $10 billion in Series J funding, crowning it 2024's largest venture capital round. This investment brought Databricks' value to $62 billion. OpenAI and xAI also rake in large investments.\", 'title': 'AI 2024 in review: The 10 most notable AI stories of the year', 'link': 'https://iot-analytics.com/ai-2024-10-most-notable-stories/'}, {'question': 'What is the AI investment trend in 2024?', 'snippet': '2024 was the third largest year on record for VC investment. AI-driven deals continued to elevate VC activity, increasing by fivefold since Q4 2023, representing over 60% of all Q4 fundraising. While VC investment amounts rose, deal volume fell below the 10,000-mark for the year for the first time since 2012.', 'title': 'Large AI deals boost investment in 2024 VC market | EY - US', 'link': 'https://www.ey.com/en_us/insights/growth/venture-capital-investment-trends'}], 'relatedSearches': [{'query': 'Top 3 ai industry trends 2024 usa'}, {'query': 'Top 3 ai industry trends 2024 pdf'}, {'query': 'AI trends 2024'}, {'query': 'Artificial intelligence Index report 2024 PDF'}, {'query': 'McKinsey AI report 2024'}, {'query': 'State of AI 2024'}, {'query': 'Global AI Index 2024'}, {'query': 'McKinsey generative AI report pdf 2024'}], 'credits': 1}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: The search results provide a good starting point.  Several sources mention Generative AI, advancements in accessibility/usability of AI tools, and increased focus on AI ethics and regulation. I will refine my search to confirm and expand on these themes.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"Generative AI advancements 2024, ethical considerations of AI, AI accessibility trends\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'Generative AI advancements 2024, ethical considerations of AI, AI accessibility trends', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Top AI & Generative AI Trends for 2024: Investor Insights, Ethical ...', 'link': 'https://medium.com/@sabine_vdl/top-ai-generative-ai-trends-for-2024-investor-insights-ethical-considerations-and-best-23274d5c33fb', 'snippet': 'Respect for Human Autonomy: AI systems should empower humans to make their own decisions rather than undermining human autonomy. Prevention of ...', 'position': 1}, {'title': 'Top 10: AI Trends in 2024 - AI Magazine', 'link': 'https://aimagazine.com/top10/top-10-ai-trends-in-2024', 'snippet': 'The biggest AI trends of 2024 included accessibility, ethics, sustainability and regulation, with companies like Google, NVIDIA and Amazon in leading roles.', 'position': 2}, {'title': 'The Evolution and Ethical Considerations of Generative AI in 2024', 'link': 'https://www.rapidinnovation.io/post/leveraging-generative-ai-ethical-frameworks-sustainable-innovation-2024', 'snippet': 'Explore the transformative impact of generative AI across industries in 2024, highlighting advancements in content creation and ethical challenges like bias ...', 'position': 3}, {'title': 'AI Evolution in 2024: Trends, Technologies, and Ethical ...', 'link': 'https://www.rapidinnovation.io/post/next-gen-ai-2024-enhancing-human-ai-collaboration', 'snippet': 'One of the primary concerns in the development of ethical AI systems is the potential for AI to cause harm, either intentionally or unintentionally. For ...', 'position': 4}, {'title': 'Generative AI Governance in 2024: An Overview - Centraleyes', 'link': 'https://www.centraleyes.com/generative-ai-governance/', 'snippet': 'Clarity on using copyright-protected material and adherence to legal frameworks are essential aspects of ethical generative AI governance. Other Challenges and ...', 'position': 5}, {'title': 'Ethical Use of Artificial Intelligence for Scientific Writing: Current ...', 'link': 'https://pmc.ncbi.nlm.nih.gov/articles/PMC11015711/', 'snippet': 'Generative AI is new and requires a reset of the current standards of practice in scientific inquiry and publication so that they are inclusive of the breadth ...', 'position': 6}, {'title': 'Attending to Bias, Accessibility, and Ethical Concerns in the Use of ...', 'link': 'https://www.edtechdigest.com/2024/11/20/attending-to-bias-accessibility-and-ethical-concerns-in-the-use-of-ai-in-education/', 'snippet': 'One of the key ethical concerns with AI in education is the need for transparency and accountability.', 'position': 7}, {'title': 'The most important AI trends in 2024 - IBM', 'link': 'https://www.ibm.com/think/insights/artificial-intelligence-trends', 'snippet': 'Adapting to emerging trends is essential to maximizing potential, minimizing risk and responsibly scaling generative AI adoption.', 'position': 8}, {'title': 'Generative AI for 2024: Security and Ethical Concerns - ITSecurityWire', 'link': 'https://itsecuritywire.com/featured/generative-ai-for-2024-security-and-ethical-concerns/', 'snippet': 'The ethical development and implementation of GenAI demand careful attention to governance, data ethics, and privacy. Building strict rules and ...', 'position': 9}, {'title': 'Striking a Balance: Navigating the Ethical Dilemmas of AI in Higher ...', 'link': 'https://er.educause.edu/articles/2024/12/striking-a-balance-navigating-the-ethical-dilemmas-of-ai-in-higher-education', 'snippet': 'One of the most pressing issues associated with AI is its potential to perpetuate and even deepen social inequities. Because AI algorithms are ...', 'position': 10}], 'peopleAlsoAsk': [{'question': 'What are the ethical issues of AI in 2024?', 'snippet': 'Bias and Fairness in AI: One of the primary ethical challenges of AI in 2024 is the issue of bias and fairness. AI systems, like any other technology, are created by humans and can inherit human biases.', 'title': 'Ethical AI Challenges in 2024: Staffing & Human Capital', 'link': 'https://resourceemployment.com/pages/ethical-ai-navigating-themoral-challenges-of-ai-in-2024'}, {'question': 'What are the trends for generative AI in 2024?', 'snippet': 'Generative AI usage jumped from 55% in 2023 to 75% in 2024. For every $1 a company invests in generative AI, the ROI is $3.7x. The top leaders using generative AI are realizing an ROI of $10.3. On average, AI deployments are taking less than 8 months and organizations are realizing value within 13 months.', 'title': \"IDC's 2024 AI opportunity study: Top five AI trends to watch - The Official ...\", 'link': 'https://blogs.microsoft.com/blog/2024/11/12/idcs-2024-ai-opportunity-study-top-five-ai-trends-to-watch/'}, {'question': 'What are the ethical considerations of generative AI?', 'snippet': 'Ensuring ethical AI development and usage requires a critical analysis of its interconnected societal and ecological implications. This work involves addressing issues such as privacy, accountability, integrity, intellectual property, bias, and human labour.', 'title': 'Research Guides: Generative Artificial Intelligence: Ethical Considerations', 'link': 'https://libguides.usask.ca/gen_ai/ethical'}, {'question': 'What are 5 ethical considerations in AI use?', 'snippet': 'COMMON ETHICAL CHALLENGES IN AI\\nInconclusive evidence. ...\\nInscrutable evidence. ...\\nMisguided evidence. ...\\nUnfair outcomes. ...\\nTransformative effects. ...\\nTraceability.', 'title': 'Common ethical challenges in AI - Human Rights and Biomedicine', 'link': 'https://www.coe.int/en/web/human-rights-and-biomedicine/common-ethical-challenges-in-ai'}], 'relatedSearches': [{'query': 'Generative AI PDF 2024'}, {'query': 'Gen AI governance'}, {'query': 'AI governance PDF'}, {'query': 'Deloitte AI governance'}, {'query': 'World Economic Forum AI Governance'}], 'credits': 1}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Three major trends are shaping the AI industry in 2024:\n",
            "\n",
            "1. **The Rise of Generative AI:** Generative AI, capable of creating various forms of content like text, images, and code, has experienced explosive growth.  Its applications span numerous sectors, from marketing and content creation to drug discovery and software development.  However, this rapid advancement necessitates a parallel focus on ethical considerations. Concerns regarding copyright infringement, the spread of misinformation, and potential biases embedded within these models require careful attention and robust regulatory frameworks. The long-term impact hinges on successfully navigating these challenges to harness its transformative potential responsibly.\n",
            "\n",
            "2. **Increased Focus on AI Accessibility and Usability:**  The AI industry is witnessing a concerted effort to make AI tools more accessible to a wider range of users, regardless of their technical expertise.  This includes developing user-friendly interfaces, lowering the barrier to entry for developers, and creating more intuitive platforms.  This trend is democratizing AI, fostering broader adoption and innovation across various sectors.  The success of this democratization hinges upon addressing potential issues of equitable access and preventing the creation of tools that exacerbate existing inequalities.\n",
            "\n",
            "\n",
            "3. **Growing Emphasis on AI Ethics and Regulation:** The increasing power and pervasiveness of AI systems are fueling a global conversation about ethical considerations and the need for responsible regulation.  This involves addressing issues like algorithmic bias, data privacy, transparency, and accountability. Governments and organizations are increasingly enacting policies and guidelines to mitigate potential harms and ensure the ethical development and deployment of AI.  The long-term effectiveness of this trend will depend on the ability of regulatory bodies to keep pace with the rapid advancements in AI technology while promoting innovation.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mWrite an engaging blog post about the AI industry, based on the research analyst’s summary. Draw inspiration from the latest blog posts in the directory.Step 1: The Content Writer will use the 'List files in directory' tool to obtain a list of all blog posts within the './blog-posts' directory.  This provides a source of inspiration for tone, style, and structure. \n",
            "Step 2: The writer will review the list of blog posts and select a few examples that showcase engaging writing styles relevant to the AI industry. The selection criteria should include: readability, use of examples, clarity of explanation and overall tone. \n",
            "Step 3: The Content Writer will receive the summary from the Market Research Analyst (output of Task 1). \n",
            "Step 4: Based on the analyst's summary and the inspiration gathered from reviewing existing blog posts, the writer will craft a 4-paragraph blog post in markdown format. The first paragraph will introduce the topic and capture the reader's attention. The subsequent paragraphs will each focus on one of the top three AI trends identified by the analyst, explaining them in a clear and engaging manner without using technical jargon. The final paragraph will offer a concise conclusion summarizing the impact of these trends and hinting at future developments.  \n",
            "Step 5:  The writer will carefully review the blog post for clarity, style, and engagement. They will ensure the tone is appropriate for a general audience, avoiding complex technical language. The post will be polished to ensure a high level of readability and interest for the target audience.  The writer will utilize existing blog posts as inspiration for sentence structure, flow, and overall writing style.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mList files in directory\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "File paths: \n",
            "-\u001b[00m\n",
            "\u001b[91m \n",
            "\n",
            "I forgot the Action name, these are the only available Actions: Tool Name: List files in directory\n",
            "Tool Arguments: {}\n",
            "Tool Description: A tool that can be used to list ./blog-posts's content.\n",
            "Tool Name: Read a file's content\n",
            "Tool Arguments: {'file_path': {'description': 'Mandatory file full path to read the file', 'type': 'str'}}\n",
            "Tool Description: A tool that reads the content of a file. To use this tool, provide a 'file_path' parameter with the path to the file you want to read.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92m\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "I encountered an error: I forgot the Action name, these are the only available Actions: Tool Name: List files in directory\n",
            "Tool Arguments: {}\n",
            "Tool Description: A tool that can be used to list ./blog-posts's content.\n",
            "Tool Name: Read a file's content\n",
            "Tool Arguments: {'file_path': {'description': 'Mandatory file full path to read the file', 'type': 'str'}}\n",
            "Tool Description: A tool that reads the content of a file. To use this tool, provide a 'file_path' parameter with the path to the file you want to read.\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [List files in directory, Read a file's content]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\u001b[91m \n",
            "\n",
            "I forgot the Action name, these are the only available Actions: Tool Name: List files in directory\n",
            "Tool Arguments: {}\n",
            "Tool Description: A tool that can be used to list ./blog-posts's content.\n",
            "Tool Name: Read a file's content\n",
            "Tool Arguments: {'file_path': {'description': 'Mandatory file full path to read the file', 'type': 'str'}}\n",
            "Tool Description: A tool that reads the content of a file. To use this tool, provide a 'file_path' parameter with the path to the file you want to read.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92m\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "I encountered an error: I forgot the Action name, these are the only available Actions: Tool Name: List files in directory\n",
            "Tool Arguments: {}\n",
            "Tool Description: A tool that can be used to list ./blog-posts's content.\n",
            "Tool Name: Read a file's content\n",
            "Tool Arguments: {'file_path': {'description': 'Mandatory file full path to read the file', 'type': 'str'}}\n",
            "Tool Description: A tool that reads the content of a file. To use this tool, provide a 'file_path' parameter with the path to the file you want to read.\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [List files in directory, Read a file's content]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "# AI's Transformative 2024: Three Key Trends Shaping the Future\n",
            "\n",
            "The world of artificial intelligence is evolving at an unprecedented pace, bringing with it both incredible opportunities and significant challenges.  2024 is shaping up to be a pivotal year, marked by three major trends that are fundamentally reshaping the AI landscape and influencing its impact on our lives.  From creative tools to ethical considerations, let's explore these defining forces.\n",
            "\n",
            "\n",
            "**The Generative AI Revolution:** Imagine AI that can create anything from poems and code to images and music. This is the power of generative AI, and its rise is nothing short of explosive.  Businesses are leveraging it to boost marketing campaigns, automate content creation, and even discover new medicines. However, this transformative technology also presents serious ethical questions, concerning copyright, misinformation, and potential bias.  Addressing these concerns is critical to ensuring the responsible development and use of this powerful tool.\n",
            "\n",
            "\n",
            "**Democratizing AI: Accessibility for All:**  No longer a domain solely for tech giants and experts, AI is becoming increasingly accessible. User-friendly interfaces and simpler development platforms are breaking down barriers, allowing more people to create and utilize AI tools. This democratization fuels innovation, driving progress in countless industries.  However, this progress must be inclusive, preventing the creation of tools that exacerbate existing inequalities and ensuring everyone can benefit from AI's transformative power.\n",
            "\n",
            "\n",
            "**Ethics and Regulation Take Center Stage:**  With the growing influence of AI, the need for clear ethical guidelines and robust regulations is more pressing than ever. Governments and organizations are working together to address concerns like algorithmic bias, data privacy, and transparency.  Establishing effective frameworks will be key to balancing the need for innovation with the responsibility of minimizing potential harms and ensuring the equitable deployment of AI technology for the benefit of all.\n",
            "\n",
            "\n",
            "The AI industry in 2024 is a dynamic mix of innovation and responsibility.  The trends outlined above demonstrate the transformative potential of AI, alongside the essential need for careful consideration of its ethical implications. As the technology continues to evolve at a breathtaking pace, navigating these challenges will be key to unlocking its full potential for a better future.\u001b[00m\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CrewOutput(raw=\"# AI's Transformative 2024: Three Key Trends Shaping the Future\\n\\nThe world of artificial intelligence is evolving at an unprecedented pace, bringing with it both incredible opportunities and significant challenges.  2024 is shaping up to be a pivotal year, marked by three major trends that are fundamentally reshaping the AI landscape and influencing its impact on our lives.  From creative tools to ethical considerations, let's explore these defining forces.\\n\\n\\n**The Generative AI Revolution:** Imagine AI that can create anything from poems and code to images and music. This is the power of generative AI, and its rise is nothing short of explosive.  Businesses are leveraging it to boost marketing campaigns, automate content creation, and even discover new medicines. However, this transformative technology also presents serious ethical questions, concerning copyright, misinformation, and potential bias.  Addressing these concerns is critical to ensuring the responsible development and use of this powerful tool.\\n\\n\\n**Democratizing AI: Accessibility for All:**  No longer a domain solely for tech giants and experts, AI is becoming increasingly accessible. User-friendly interfaces and simpler development platforms are breaking down barriers, allowing more people to create and utilize AI tools. This democratization fuels innovation, driving progress in countless industries.  However, this progress must be inclusive, preventing the creation of tools that exacerbate existing inequalities and ensuring everyone can benefit from AI's transformative power.\\n\\n\\n**Ethics and Regulation Take Center Stage:**  With the growing influence of AI, the need for clear ethical guidelines and robust regulations is more pressing than ever. Governments and organizations are working together to address concerns like algorithmic bias, data privacy, and transparency.  Establishing effective frameworks will be key to balancing the need for innovation with the responsibility of minimizing potential harms and ensuring the equitable deployment of AI technology for the benefit of all.\\n\\n\\nThe AI industry in 2024 is a dynamic mix of innovation and responsibility.  The trends outlined above demonstrate the transformative potential of AI, alongside the essential need for careful consideration of its ethical implications. As the technology continues to evolve at a breathtaking pace, navigating these challenges will be key to unlocking its full potential for a better future.\", pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Research the latest trends in the AI industry and provide a summary.Step 1: The Market Research Analyst will utilize the \\'Search the internet with Serper\\' tool.  The search query will be crafted to be highly specific and effective, for example:  \"Top 3 AI industry trends 2024\", \"Most significant advancements in artificial intelligence\",  \"Breakthroughs in AI research this year\".  The analyst will ensure the search query is modified and iterated upon to refine the results, focusing on reputable sources like academic journals, industry publications (e.g., MIT Technology Review, IEEE Spectrum), and news from major technology companies. \\nStep 2:  The analyst will carefully review the top 10 results (or adjust the number based on the relevance of initial results) provided by Serper, identifying common themes and unique perspectives across various sources.  They will prioritize high-quality, peer-reviewed articles and reputable news outlets to ensure accuracy and depth of analysis. \\nStep 3:  The analyst will synthesize the information gathered, focusing on identifying the top three trending AI developments.  This summary should not just be a list; it should analyze the significance and potential impact of each trend, providing a unique perspective on their implications for the broader AI industry and other sectors. The summary should be concise and easily understandable, avoiding overly technical jargon.\\nStep 4:  The analyst will review the summary for clarity, accuracy, and overall impact. They will ensure the unique perspective is clearly articulated and well-supported by the evidence gathered. The final summary will be concise, factual and insightful, ready for the content writer.', name=None, expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.', summary='Research the latest trends in the AI industry and provide...', raw='Three major trends are shaping the AI industry in 2024:\\n\\n1. **The Rise of Generative AI:** Generative AI, capable of creating various forms of content like text, images, and code, has experienced explosive growth.  Its applications span numerous sectors, from marketing and content creation to drug discovery and software development.  However, this rapid advancement necessitates a parallel focus on ethical considerations. Concerns regarding copyright infringement, the spread of misinformation, and potential biases embedded within these models require careful attention and robust regulatory frameworks. The long-term impact hinges on successfully navigating these challenges to harness its transformative potential responsibly.\\n\\n2. **Increased Focus on AI Accessibility and Usability:**  The AI industry is witnessing a concerted effort to make AI tools more accessible to a wider range of users, regardless of their technical expertise.  This includes developing user-friendly interfaces, lowering the barrier to entry for developers, and creating more intuitive platforms.  This trend is democratizing AI, fostering broader adoption and innovation across various sectors.  The success of this democratization hinges upon addressing potential issues of equitable access and preventing the creation of tools that exacerbate existing inequalities.\\n\\n\\n3. **Growing Emphasis on AI Ethics and Regulation:** The increasing power and pervasiveness of AI systems are fueling a global conversation about ethical considerations and the need for responsible regulation.  This involves addressing issues like algorithmic bias, data privacy, transparency, and accountability. Governments and organizations are increasingly enacting policies and guidelines to mitigate potential harms and ensure the ethical development and deployment of AI.  The long-term effectiveness of this trend will depend on the ability of regulatory bodies to keep pace with the rapid advancements in AI technology while promoting innovation.', pydantic=None, json_dict=None, agent='Market Research Analyst', output_format=<OutputFormat.RAW: 'raw'>), TaskOutput(description=\"Write an engaging blog post about the AI industry, based on the research analyst’s summary. Draw inspiration from the latest blog posts in the directory.Step 1: The Content Writer will use the 'List files in directory' tool to obtain a list of all blog posts within the './blog-posts' directory.  This provides a source of inspiration for tone, style, and structure. \\nStep 2: The writer will review the list of blog posts and select a few examples that showcase engaging writing styles relevant to the AI industry. The selection criteria should include: readability, use of examples, clarity of explanation and overall tone. \\nStep 3: The Content Writer will receive the summary from the Market Research Analyst (output of Task 1). \\nStep 4: Based on the analyst's summary and the inspiration gathered from reviewing existing blog posts, the writer will craft a 4-paragraph blog post in markdown format. The first paragraph will introduce the topic and capture the reader's attention. The subsequent paragraphs will each focus on one of the top three AI trends identified by the analyst, explaining them in a clear and engaging manner without using technical jargon. The final paragraph will offer a concise conclusion summarizing the impact of these trends and hinting at future developments.  \\nStep 5:  The writer will carefully review the blog post for clarity, style, and engagement. They will ensure the tone is appropriate for a general audience, avoiding complex technical language. The post will be polished to ensure a high level of readability and interest for the target audience.  The writer will utilize existing blog posts as inspiration for sentence structure, flow, and overall writing style.\", name=None, expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.', summary='Write an engaging blog post about the AI industry, based...', raw=\"# AI's Transformative 2024: Three Key Trends Shaping the Future\\n\\nThe world of artificial intelligence is evolving at an unprecedented pace, bringing with it both incredible opportunities and significant challenges.  2024 is shaping up to be a pivotal year, marked by three major trends that are fundamentally reshaping the AI landscape and influencing its impact on our lives.  From creative tools to ethical considerations, let's explore these defining forces.\\n\\n\\n**The Generative AI Revolution:** Imagine AI that can create anything from poems and code to images and music. This is the power of generative AI, and its rise is nothing short of explosive.  Businesses are leveraging it to boost marketing campaigns, automate content creation, and even discover new medicines. However, this transformative technology also presents serious ethical questions, concerning copyright, misinformation, and potential bias.  Addressing these concerns is critical to ensuring the responsible development and use of this powerful tool.\\n\\n\\n**Democratizing AI: Accessibility for All:**  No longer a domain solely for tech giants and experts, AI is becoming increasingly accessible. User-friendly interfaces and simpler development platforms are breaking down barriers, allowing more people to create and utilize AI tools. This democratization fuels innovation, driving progress in countless industries.  However, this progress must be inclusive, preventing the creation of tools that exacerbate existing inequalities and ensuring everyone can benefit from AI's transformative power.\\n\\n\\n**Ethics and Regulation Take Center Stage:**  With the growing influence of AI, the need for clear ethical guidelines and robust regulations is more pressing than ever. Governments and organizations are working together to address concerns like algorithmic bias, data privacy, and transparency.  Establishing effective frameworks will be key to balancing the need for innovation with the responsibility of minimizing potential harms and ensuring the equitable deployment of AI technology for the benefit of all.\\n\\n\\nThe AI industry in 2024 is a dynamic mix of innovation and responsibility.  The trends outlined above demonstrate the transformative potential of AI, alongside the essential need for careful consideration of its ethical implications. As the technology continues to evolve at a breathtaking pace, navigating these challenges will be key to unlocking its full potential for a better future.\", pydantic=None, json_dict=None, agent='Content Writer', output_format=<OutputFormat.RAW: 'raw'>)], token_usage=UsageMetrics(total_tokens=14655, prompt_tokens=13566, cached_prompt_tokens=0, completion_tokens=1089, successful_requests=7))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "# Importing crewAI tools\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")\n",
        "\n",
        "# Set up API keys\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY') # serper.dev API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\n",
        "\n",
        "# Instantiate tools\n",
        "docs_tool = DirectoryReadTool(directory='./blog-posts')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()\n",
        "\n",
        "# Create agents\n",
        "researcher = Agent(\n",
        "    role='Market Research Analyst',\n",
        "    goal='Provide up-to-date market analysis of the AI industry',\n",
        "    backstory='An expert analyst with a keen eye for market trends.',\n",
        "    tools=[search_tool, web_rag_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "    role='Content Writer',\n",
        "    goal='Craft engaging blog posts about the AI industry',\n",
        "    backstory='A skilled writer with a passion for technology.',\n",
        "    tools=[docs_tool, file_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "# Define tasks\n",
        "research = Task(\n",
        "    description='Research the latest trends in the AI industry and provide a summary.',\n",
        "    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',\n",
        "    agent=researcher\n",
        ")\n",
        "\n",
        "write = Task(\n",
        "    description='Write an engaging blog post about the AI industry, based on the research analyst’s summary. Draw inspiration from the latest blog posts in the directory.',\n",
        "    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',\n",
        "    agent=writer,\n",
        "    output_file='blog-posts/new_post.md'  # The final blog post will be saved here\n",
        ")\n",
        "\n",
        "# Assemble a crew with planning enabled\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer],\n",
        "    tasks=[research, write],\n",
        "    verbose=True,\n",
        "    planning=True,\n",
        "    planning_llm=llm1 # Enable planning feature\n",
        ")\n",
        "\n",
        "# Execute tasks\n",
        "crew.kickoff()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "wSTOexDIdiaH",
        "outputId": "e45cf501-e541-4f7b-c6b9-d8693568f919"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "# Results of CrewAI execution\n\nThe code you provided executes a series of tasks using the CrewAI library.  It involves:\n\n1. **Basic CrewAI Setup and Execution:** The code starts with a simple demonstration of CrewAI's `Flow` class, printing \"Daniyal\" and then \"Salman\". It then proceeds to utilize a Gemini language model to answer a question.\n\n2. **Agent with Knowledge Source:** An agent is created with a specific goal and backstory. A knowledge source is created using a string containing information about a user named Habib. The agent then answers a question about Habib using this knowledge.\n\n3. **Crew with Memory:** This part of the code creates a Crew with three types of memory: Long Term Memory, Short Term Memory, and Entity Memory.  These memories are stored using different storage mechanisms, potentially using a SQLite database for LTM and Vector databases for STM and EM.\n\n4. **Mem0 Integration:** Mem0 is integrated with the CrewAI pipeline by creating a Mem0 client and then configuring the crew to utilize Mem0 for user memory storage.  This allows the crew to access past interactions with the user to answer questions about their preferences.\n\n5. **AI Teacher Agent with Code Interpreter:** An agent named \"AI Teacher\" is created to evaluate student Python code.  It utilizes the `CodeInterpreterTool` from the `crewai_tools` library.  A sample question and solution are provided for the AI teacher to assess.\n\n6. **Market Research and Content Creation:** The final section creates two agents: a researcher and a writer. The researcher uses search tools (SerperDevTool and WebsiteSearchTool) to find the latest AI industry trends, and the writer creates a blog post about those trends based on the research. It also leverages existing blog posts in a directory using the DirectoryReadTool and FileReadTool.  The `planning=True` setting enables CrewAI's task planning capabilities.\n\n**To run this code successfully, you need to:**\n\n* **Set up your API keys:** Replace placeholders like `userdata.get('GOOGLE_API_KEY')`, `userdata.get('MEM0_API_KEY')`, `userdata.get('SERPER_API_KEY')`, and `os.environ[\"OPENAI_API_KEY\"]` with your actual API keys.\n* **Install necessary libraries:** Ensure that all dependencies are correctly installed in the colab environment.\n* **Configure file paths:** Make sure that file paths like `'./my_crew2'` and `'./blog-posts'` are correct and that the `blog-posts` directory exists and contains some blog posts if that is the way you are running it.\n\n\n**Expected output:**\n\nThe code will output the results of each stage of the CrewAI workflow, including the answers to the various questions posed to the agents. Specifically, the AI Teacher's evaluation of the student code, the research summary produced by the researcher, and the final blog post generated by the writer.  The output may vary depending on the LLM and the provided inputs.\n\n\nThis Markdown cell provides a summary of the notebook's code, including key steps, API keys requirements and potential outputs.\n",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt: import markdown for jupyter display for upper cell\n",
        "\n",
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(\"\"\"# Results of CrewAI execution\n",
        "\n",
        "The code you provided executes a series of tasks using the CrewAI library.  It involves:\n",
        "\n",
        "1. **Basic CrewAI Setup and Execution:** The code starts with a simple demonstration of CrewAI's `Flow` class, printing \"Daniyal\" and then \"Salman\". It then proceeds to utilize a Gemini language model to answer a question.\n",
        "\n",
        "2. **Agent with Knowledge Source:** An agent is created with a specific goal and backstory. A knowledge source is created using a string containing information about a user named Habib. The agent then answers a question about Habib using this knowledge.\n",
        "\n",
        "3. **Crew with Memory:** This part of the code creates a Crew with three types of memory: Long Term Memory, Short Term Memory, and Entity Memory.  These memories are stored using different storage mechanisms, potentially using a SQLite database for LTM and Vector databases for STM and EM.\n",
        "\n",
        "4. **Mem0 Integration:** Mem0 is integrated with the CrewAI pipeline by creating a Mem0 client and then configuring the crew to utilize Mem0 for user memory storage.  This allows the crew to access past interactions with the user to answer questions about their preferences.\n",
        "\n",
        "5. **AI Teacher Agent with Code Interpreter:** An agent named \"AI Teacher\" is created to evaluate student Python code.  It utilizes the `CodeInterpreterTool` from the `crewai_tools` library.  A sample question and solution are provided for the AI teacher to assess.\n",
        "\n",
        "6. **Market Research and Content Creation:** The final section creates two agents: a researcher and a writer. The researcher uses search tools (SerperDevTool and WebsiteSearchTool) to find the latest AI industry trends, and the writer creates a blog post about those trends based on the research. It also leverages existing blog posts in a directory using the DirectoryReadTool and FileReadTool.  The `planning=True` setting enables CrewAI's task planning capabilities.\n",
        "\n",
        "**To run this code successfully, you need to:**\n",
        "\n",
        "* **Set up your API keys:** Replace placeholders like `userdata.get('GOOGLE_API_KEY')`, `userdata.get('MEM0_API_KEY')`, `userdata.get('SERPER_API_KEY')`, and `os.environ[\"OPENAI_API_KEY\"]` with your actual API keys.\n",
        "* **Install necessary libraries:** Ensure that all dependencies are correctly installed in the colab environment.\n",
        "* **Configure file paths:** Make sure that file paths like `'./my_crew2'` and `'./blog-posts'` are correct and that the `blog-posts` directory exists and contains some blog posts if that is the way you are running it.\n",
        "\n",
        "\n",
        "**Expected output:**\n",
        "\n",
        "The code will output the results of each stage of the CrewAI workflow, including the answers to the various questions posed to the agents. Specifically, the AI Teacher's evaluation of the student code, the research summary produced by the researcher, and the final blog post generated by the writer.  The output may vary depending on the LLM and the provided inputs.\n",
        "\n",
        "\n",
        "This Markdown cell provides a summary of the notebook's code, including key steps, API keys requirements and potential outputs.\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ-OsSM69To9"
      },
      "source": [
        "#Create your own Tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7HCLtNf9YvI"
      },
      "outputs": [],
      "source": [
        "from crewai.tools import BaseTool\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Type\n",
        "\n",
        "class MyToolInput(BaseModel):\n",
        "  \"\"\"Input schema for MyCustumTool.\"\"\"\n",
        "  student_name: str = Field(..., description=\"Name of the student\")\n",
        "  student_roll_no: int = Field(..., description=\"Student id\")\n",
        "\n",
        "class PiaicStudentCard(BaseTool):\n",
        "  name: str = \"Piaic student card generator\"\n",
        "  description: str = \"this function will create Piaic student card\"\n",
        "  args_schema: Type[BaseModel] = MyToolInput\n",
        "\n",
        "  def _run(self, student_name: str, student_roll_no: int )-> str:\n",
        "    return f\"\"\"PIAIC student card\n",
        "\n",
        "student name : {student_name}\n",
        "student roll no : {student_roll_no}\n",
        "Pakistan zindabad\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Glq1tqG21mAw"
      },
      "outputs": [],
      "source": [
        "from crewai.tools import tool\n",
        "\n",
        "@tool(\"PIAIC fee update\")\n",
        "def my_tool(roll_no: int) -> dict | str:\n",
        "  \"\"\"this function search piaic student fee update, it will required roll no of PIAIC student\"\"\"\n",
        "  #database\n",
        "  data ={100:'paid',\n",
        "         200:'unpaid'}\n",
        "\n",
        "  status = data.get(roll_no)\n",
        "\n",
        "  if status:\n",
        "    return {\"status\": status}\n",
        "  else:\n",
        "    return \"student not found\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xo8UuMt2hyw",
        "outputId": "99a02baa-125c-4e23-9c8a-e4c51378cff5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou will be responsible for all PIAIC relevant operations, student query 'i am PIAIC student my name is Habib ur Rehman and my roll number is 96 , generate a card for me.' you must be know how to answer his question \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mPiaic student card generator\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"student_name\\\": \\\"Habib ur Rehman\\\", \\\"student_roll_no\\\": 96}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "PIAIC student card\n",
            "\n",
            "student name : Habib ur Rehman\n",
            "student roll no : 96\n",
            "Pakistan zindabad\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "PIAIC student card\n",
            "\n",
            "student name : Habib ur Rehman\n",
            "student roll no : 96\n",
            "Pakistan zindabad\u001b[00m\n",
            "\n",
            "\n",
            "PIAIC student card\n",
            "\n",
            "student name : Habib ur Rehman\n",
            "student roll no : 96\n",
            "Pakistan zindabad\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# Use the new tool\n",
        "card = PiaicStudentCard()\n",
        "\n",
        "piaic_manager = Agent(\n",
        "    role = \"PIAIC manager\",\n",
        "    goal = \"Manage all quries regarding PIAIC and you will use only relevant tools for student query\",\n",
        "    backstory =\"\"\"you are a master at understanding people and their preferences.\"\"\",\n",
        "    tools = [card, my_tool],\n",
        "    verbose = True,\n",
        "    llm=llm1\n",
        ")\n",
        "piaic_card_creater = Task(\n",
        "    description=\"you will be responsible for all PIAIC relevant operations, student query '{query}' you must be know how to answer his question \",\n",
        "    expected_output=\"final query answer only\",\n",
        "    agent=piaic_manager  # Fixed: Changed piaic_manager to fee_manager\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[piaic_manager],\n",
        "    tasks=[piaic_card_creater],\n",
        "    verbose=True\n",
        "\n",
        ")\n",
        "result = crew.kickoff(inputs={\n",
        "    \"query\": \"i am PIAIC student my name is Habib ur Rehman and my roll number is 96 , generate a card for me.\"\n",
        "\n",
        "})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeVf_73NgP9D",
        "outputId": "570f5a22-a935-4328-de20-0734227a648b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou will be responsible for all PIAIC relevant operations, student query 'i am PIAIC student my name is Habib ur Rehman and my roll number is 200 , can you share my fee updates.' you must be know how to answer his question \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mPIAIC fee update\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"roll_no\\\": 200}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'status': 'unpaid'}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Your fee status is unpaid.\u001b[00m\n",
            "\n",
            "\n",
            "Your fee status is unpaid.\n"
          ]
        }
      ],
      "source": [
        "result = crew.kickoff(inputs={\n",
        "    \"query\": \"i am PIAIC student my name is Habib ur Rehman and my roll number is 200 , can you share my fee updates.\"\n",
        "\n",
        "})\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsca44t0r9HB"
      },
      "source": [
        "#Processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24O9ICgGq3jp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19e01444-b2f2-4abe-df41-acd578c1681c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mGenerate a list of 5 intresting ideas for an article, then write one captivating paragraph\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92m```tool_code\n",
            "Thought:I need to delegate the task of generating interesting article ideas to the Researcher.  Then I will ask the senior_writer to write a captivating paragraph based on the best idea.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"task\\\": {\\\"description\\\": \\\"Generate 5 interesting article ideas for a blog post about productivity techniques.\\\", \\\"type\\\": \\\"str\\\"}, \\\"context\\\": {\\\"description\\\": \\\"The article should focus on practical, actionable productivity tips that resonate with a wide audience.  The ideas should be diverse and cover different aspects of productivity, such as time management, focus, organization, etc.  Please provide a brief explanation of each idea, no more than 2 sentences per idea. The target audience is professionals and students interested in improving their productivity.\\\", \\\"type\\\": \\\"str\\\"}, \\\"coworker\\\": {\\\"description\\\": \\\"Researcher\\\", \\\"type\\\": \\\"str\\\"}}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: unhashable type: 'dict'.\n",
            " Tool Delegate work to coworker accepts these inputs: Tool Name: Delegate work to coworker\n",
            "Tool Arguments: {'task': {'description': 'The task to delegate', 'type': 'str'}, 'context': {'description': 'The context for the task', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to delegate to', 'type': 'str'}}\n",
            "Tool Description: Delegate a specific task to one of the following coworkers: Researcher, senior_writer\n",
            "The input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Delegate work to coworker, Ask question to coworker]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mGenerate 5 interesting article ideas for a blog post about productivity techniques.\u001b[00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/colab/html/_background_server.py:103: DeprecationWarning: make_current is deprecated; start the event loop first\n",
            "  ioloop.make_current()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\u001b[91m \n",
            "\n",
            "Failed to convert text into a Pydantic model due to the following error: litellm.BadRequestError: VertexAIException BadRequestError - {\n",
            "  \"error\": {\n",
            "    \"code\": 400,\n",
            "    \"message\": \"* GenerateContentRequest.tools[0].function_declarations[0].parameters.properties[arguments].properties: should be non-empty for OBJECT type\\n\",\n",
            "    \"status\": \"INVALID_ARGUMENT\"\n",
            "  }\n",
            "}\n",
            "\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92m```tool_code\n",
            "Thought:I need to generate 5 interesting article ideas for a blog post about productivity techniques.  Since I don't have access to external resources to brainstorm, I will use my knowledge base to come up with ideas that are practical and actionable, covering various aspects of productivity.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mNone\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "I encountered an error: Failed to convert text into a Pydantic model due to the following error: litellm.BadRequestError: VertexAIException BadRequestError - {\n",
            "  \"error\": {\n",
            "    \"code\": 400,\n",
            "    \"message\": \"* GenerateContentRequest.tools[0].function_declarations[0].parameters.properties[arguments].properties: should be non-empty for OBJECT type\\n\",\n",
            "    \"status\": \"INVALID_ARGUMENT\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [List files in directory, Read a file's content]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\u001b[91m \n",
            "\n",
            "Failed to convert text into a Pydantic model due to the following error: litellm.BadRequestError: VertexAIException BadRequestError - {\n",
            "  \"error\": {\n",
            "    \"code\": 400,\n",
            "    \"message\": \"* GenerateContentRequest.tools[0].function_declarations[0].parameters.properties[arguments].properties: should be non-empty for OBJECT type\\n\",\n",
            "    \"status\": \"INVALID_ARGUMENT\"\n",
            "  }\n",
            "}\n",
            "\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I will generate the article ideas directly, since I don't have access to any files to read.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mNone\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "I encountered an error: Failed to convert text into a Pydantic model due to the following error: litellm.BadRequestError: VertexAIException BadRequestError - {\n",
            "  \"error\": {\n",
            "    \"code\": 400,\n",
            "    \"message\": \"* GenerateContentRequest.tools[0].function_declarations[0].parameters.properties[arguments].properties: should be non-empty for OBJECT type\\n\",\n",
            "    \"status\": \"INVALID_ARGUMENT\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [List files in directory, Read a file's content]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "1. **The Power of Time Blocking:** Divide your day into specific blocks dedicated to particular tasks. This structured approach minimizes context switching and enhances focus, leading to increased productivity.\n",
            "\n",
            "2. **Mastering the Art of Prioritization:** Learn effective prioritization techniques like the Eisenhower Matrix (urgent/important). This helps you focus on high-impact tasks first, maximizing your output and reducing stress.\n",
            "\n",
            "3. **The Pomodoro Technique for Focused Work:** Use the Pomodoro Technique—25 minutes of focused work followed by a 5-minute break—to maintain concentration and prevent burnout. This structured approach can significantly improve your focus and efficiency.\n",
            "\n",
            "4. **Harnessing the Potential of Technology:** Explore productivity apps and tools to streamline your workflow.  Calendar apps, note-taking software, and task managers can help you organize and manage your time effectively.\n",
            "\n",
            "5. **The Importance of Regular Breaks and Self-Care:** Incorporate regular breaks into your schedule to avoid burnout.  Taking short breaks throughout the day to rest and recharge can improve your overall focus and productivity.\u001b[00m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought:Let's try again, providing the inputs as strings rather than dictionaries within a dictionary.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"task\\\": \\\"Generate 5 interesting article ideas for a blog post about productivity techniques.\\\", \\\"context\\\": \\\"The article should focus on practical, actionable productivity tips that resonate with a wide audience. The ideas should be diverse and cover different aspects of productivity, such as time management, focus, organization, etc. Please provide a brief explanation of each idea, no more than 2 sentences per idea. The target audience is professionals and students interested in improving their productivity.\\\", \\\"coworker\\\": \\\"Researcher\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "1. **The Power of Time Blocking:** Divide your day into specific blocks dedicated to particular tasks. This structured approach minimizes context switching and enhances focus, leading to increased productivity.\n",
            "\n",
            "2. **Mastering the Art of Prioritization:** Learn effective prioritization techniques like the Eisenhower Matrix (urgent/important). This helps you focus on high-impact tasks first, maximizing your output and reducing stress.\n",
            "\n",
            "3. **The Pomodoro Technique for Focused Work:** Use the Pomodoro Technique—25 minutes of focused work followed by a 5-minute break—to maintain concentration and prevent burnout. This structured approach can significantly improve your focus and efficiency.\n",
            "\n",
            "4. **Harnessing the Potential of Technology:** Explore productivity apps and tools to streamline your workflow.  Calendar apps, note-taking software, and task managers can help you organize and manage your time effectively.\n",
            "\n",
            "5. **The Importance of Regular Breaks and Self-Care:** Incorporate regular breaks into your schedule to avoid burnout.  Taking short breaks throughout the day to rest and recharge can improve your overall focus and productivity.\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92msenior_writer\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mWrite a captivating paragraph about the importance of mastering the art of prioritization for improved productivity.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92msenior_writer\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "In today's fast-paced world, mastering the art of prioritization isn't just a helpful skill—it's a necessity.  Effective prioritization isn't about cramming more into your day; it's about strategically focusing your energy on what truly matters, leading to dramatically increased efficiency and a significant reduction in stress.  Imagine sailing a ship: without a clear destination and a prioritized course of action, you’re adrift.  Similarly, without prioritizing tasks, you'll be constantly reacting instead of proactively achieving your goals.  One incredibly effective technique is the Eisenhower Matrix, which categorizes tasks based on urgency and importance.  Urgent and important tasks require immediate attention, while important but not urgent tasks should be scheduled.  Urgent but unimportant tasks should be delegated if possible, and tasks that are neither urgent nor important should be eliminated entirely. By strategically employing this simple framework, you can navigate your workload with clarity, focus on high-impact activities, and reclaim valuable time and mental energy, ultimately leading to a more productive and fulfilling life.\u001b[00m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92m```\n",
            "```tool_code\n",
            "Thought:The Researcher provided 5 good ideas. Now I need the senior_writer to craft a captivating paragraph based on one of these ideas. I'll choose \"Mastering the Art of Prioritization\".\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"task\\\": \\\"Write a captivating paragraph about the importance of mastering the art of prioritization for improved productivity.\\\", \\\"context\\\": \\\"The paragraph should highlight the benefits of effective prioritization, such as reduced stress and increased efficiency.  It should also mention a specific technique, such as the Eisenhower Matrix (urgent/important), and explain how it works briefly. The target audience is professionals and students interested in improving their productivity.  The tone should be engaging and motivational.\\\", \\\"coworker\\\": \\\"senior_writer\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "In today's fast-paced world, mastering the art of prioritization isn't just a helpful skill—it's a necessity.  Effective prioritization isn't about cramming more into your day; it's about strategically focusing your energy on what truly matters, leading to dramatically increased efficiency and a significant reduction in stress.  Imagine sailing a ship: without a clear destination and a prioritized course of action, you’re adrift.  Similarly, without prioritizing tasks, you'll be constantly reacting instead of proactively achieving your goals.  One incredibly effective technique is the Eisenhower Matrix, which categorizes tasks based on urgency and importance.  Urgent and important tasks require immediate attention, while important but not urgent tasks should be scheduled.  Urgent but unimportant tasks should be delegated if possible, and tasks that are neither urgent nor important should be eliminated entirely. By strategically employing this simple framework, you can navigate your workload with clarity, focus on high-impact activities, and reclaim valuable time and mental energy, ultimately leading to a more productive and fulfilling life.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "* **The Power of Time Blocking:** Divide your day into specific blocks dedicated to particular tasks. This structured approach minimizes context switching and enhances focus, leading to increased productivity.\n",
            "\n",
            "* **Mastering the Art of Prioritization:** Learn effective prioritization techniques like the Eisenhower Matrix (urgent/important). This helps you focus on high-impact tasks first, maximizing your output and reducing stress.\n",
            "\n",
            "* **The Pomodoro Technique for Focused Work:** Use the Pomodoro Technique—25 minutes of focused work followed by a 5-minute break—to maintain concentration and prevent burnout. This structured approach can significantly improve your focus and efficiency.\n",
            "\n",
            "* **Harnessing the Potential of Technology:** Explore productivity apps and tools to streamline your workflow.  Calendar apps, note-taking software, and task managers can help you organize and manage your time effectively.\n",
            "\n",
            "* **The Importance of Regular Breaks and Self-Care:** Incorporate regular breaks into your schedule to avoid burnout.  Taking short breaks throughout the day to rest and recharge can improve your overall focus and productivity.\n",
            "\n",
            "\n",
            "**Captivating Paragraph (based on \"Mastering the Art of Prioritization\"):**\n",
            "\n",
            "In today's fast-paced world, mastering the art of prioritization isn't just a helpful skill—it's a necessity.  Effective prioritization isn't about cramming more into your day; it's about strategically focusing your energy on what truly matters, leading to dramatically increased efficiency and a significant reduction in stress.  Imagine sailing a ship: without a clear destination and a prioritized course of action, you’re adrift.  Similarly, without prioritizing tasks, you'll be constantly reacting instead of proactively achieving your goals.  One incredibly effective technique is the Eisenhower Matrix, which categorizes tasks based on urgency and importance.  Urgent and important tasks require immediate attention, while important but not urgent tasks should be scheduled.  Urgent but unimportant tasks should be delegated if possible, and tasks that are neither urgent nor important should be eliminated entirely. By strategically employing this simple framework, you can navigate your workload with clarity, focus on high-impact activities, and reclaim valuable time and mental energy, ultimately leading to a more productive and fulfilling life.\n",
            "```\u001b[00m\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "* **The Power of Time Blocking:** Divide your day into specific blocks dedicated to particular tasks. This structured approach minimizes context switching and enhances focus, leading to increased productivity.\n\n* **Mastering the Art of Prioritization:** Learn effective prioritization techniques like the Eisenhower Matrix (urgent/important). This helps you focus on high-impact tasks first, maximizing your output and reducing stress.\n\n* **The Pomodoro Technique for Focused Work:** Use the Pomodoro Technique—25 minutes of focused work followed by a 5-minute break—to maintain concentration and prevent burnout. This structured approach can significantly improve your focus and efficiency.\n\n* **Harnessing the Potential of Technology:** Explore productivity apps and tools to streamline your workflow.  Calendar apps, note-taking software, and task managers can help you organize and manage your time effectively.\n\n* **The Importance of Regular Breaks and Self-Care:** Incorporate regular breaks into your schedule to avoid burnout.  Taking short breaks throughout the day to rest and recharge can improve your overall focus and productivity.\n\n\n**Captivating Paragraph (based on \"Mastering the Art of Prioritization\"):**\n\nIn today's fast-paced world, mastering the art of prioritization isn't just a helpful skill—it's a necessity.  Effective prioritization isn't about cramming more into your day; it's about strategically focusing your energy on what truly matters, leading to dramatically increased efficiency and a significant reduction in stress.  Imagine sailing a ship: without a clear destination and a prioritized course of action, you’re adrift.  Similarly, without prioritizing tasks, you'll be constantly reacting instead of proactively achieving your goals.  One incredibly effective technique is the Eisenhower Matrix, which categorizes tasks based on urgency and importance.  Urgent and important tasks require immediate attention, while important but not urgent tasks should be scheduled.  Urgent but unimportant tasks should be delegated if possible, and tasks that are neither urgent nor important should be eliminated entirely. By strategically employing this simple framework, you can navigate your workload with clarity, focus on high-impact activities, and reclaim valuable time and mental energy, ultimately leading to a more productive and fulfilling life.\n```"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")\n",
        "\n",
        "# Set up API keys\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY') # serper.dev API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\n",
        "\n",
        "# Instantiate tools\n",
        "docs_tool = DirectoryReadTool(directory='./blog-posts2')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()\n",
        "\n",
        "\n",
        "researcher = Agent(\n",
        "    role = \"Researcher\",\n",
        "    goal = \"conduct through research and analysis on AI and AI agents\",\n",
        "    backstory =\"\"\"you are an expert researcher specialize in technology, software enginnering, AI and startups .\"\"\",\n",
        "    allow_delegation = False,\n",
        "    tools=[docs_tool, file_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "writer = Agent(\n",
        "    role = \"senior_writer\",\n",
        "    goal = \"create compelling content abou AI and AI agents\",\n",
        "    backstory =\"\"\"you are a senior writer specialize in technology, software enginnering, AI and startups .\"\"\",\n",
        "    allow_delegation = False,\n",
        "\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "task = Task(\n",
        "    description=\"Generate a list of 5 intresting ideas for an article, then write one captivating paragraph\",\n",
        "    expected_output=\"5 bullet point each with paragraph and accompaniying notes. \",\n",
        "\n",
        ")\n",
        "manager = Agent(\n",
        "    role = \"Project Manager\",\n",
        "    goal = \"Efficiently manage the crew ensure hight-quality task completion\",\n",
        "    backstory =\"\"\"you are an experience project manager, skilled in ocerseeing complex projects and guiding .\"\"\",\n",
        "    allow_delegation = True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer],\n",
        "    tasks=[task],\n",
        "    manager_agent=manager,\n",
        "    function_calling_llm=llm1,\n",
        "    verbose=True,\n",
        "    process=Process.hierarchical,\n",
        "\n",
        ")\n",
        "result=crew.kickoff()\n",
        "from IPython.display import Markdown\n",
        "Markdown(result.raw)\n",
        "# print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqfpqmuiM3IpZOE8/l2V82",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}